{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6793c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import glob\n",
    "from tqdm import tqdm \n",
    "import numba as nb\n",
    "from numba import njit, jit\n",
    "\n",
    "import editdistance \n",
    "import torch \n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from seq_models import SeqCNN\n",
    "from seqgen import editDist\n",
    "from seqio import FastaFile\n",
    "from config import config \n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as ex \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcfc88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_dist(a, b):\n",
    "    return 1- np.matmul(a,b)/np.linalg.norm(a)/np.linalg.norm(b)\n",
    "\n",
    "\n",
    "def cosine_sim(a, b):\n",
    "    return np.matmul(a,b)/np.linalg.norm(a)/np.linalg.norm(b)\n",
    "\n",
    "\n",
    "def load_pretrained_net( groups, kernel, num_layers, stride=2,in_channels=4, channels=1, i=0):\n",
    "    paths = glob.glob(f\"{config['networks_dir']}/*_in_channels{in_channels}_num_layers{num_layers}_channels{channels}_kernel{kernel}_stride{stride}_groups{groups}_*\")\n",
    "    print(paths)\n",
    "    net = SeqCNN(in_channels=in_channels, groups=groups, kernel=kernel, num_layers=num_layers, stride=stride, channels=channels)\n",
    "    net.load_state_dict(torch.load(paths[i]))\n",
    "    return net\n",
    "\n",
    "\n",
    "# def load_best_net(layers):\n",
    "#     best_params = {\n",
    "#         8: {}\n",
    "#     }\n",
    "\n",
    "\n",
    "def load_ed_viral():\n",
    "    df = pd.read_csv(config['viral_ed'],names=['seq1','seq2', 'ed'])\n",
    "    df.seq1 = df.seq1.apply(lambda x: x.replace('.gz',''))\n",
    "    df.seq2 = df.seq2.apply(lambda x: x.replace('.gz',''))\n",
    "    seq_names = list(df.seq1.unique()) + list(df.seq2.unique())\n",
    "    seq_names = list(set(seq_names))\n",
    "    return df, seq_names\n",
    "\n",
    "\n",
    "def save_viral_data():\n",
    "    paths = glob.glob(f\"{config['viral_dir']}/*.fna\")\n",
    "    fastafiles = [FastaFile(p) for p in tqdm(paths,total=len(paths))]\n",
    "\n",
    "    names = []\n",
    "    ids = []\n",
    "    seqs = []\n",
    "    lens = []\n",
    "    for ff in fastafiles:\n",
    "        for s in ff.seqs:\n",
    "            names.append(ff.name)\n",
    "            seqs.append(s.seq)\n",
    "            ids.append(s.id)\n",
    "            lens.append(len(s.seq))\n",
    "    np.savez('viral',name=names,seq=seqs,id=ids, len=lens)\n",
    "\n",
    "    processed = np.isin(names,seq_names)\n",
    "    \n",
    "\n",
    "class ViralDataset(Dataset):\n",
    "    def __init__(self, L, stride, samples=0):\n",
    "        super().__init__()\n",
    "        data = np.load('viral.npz',allow_pickle=True)\n",
    "        self.seqs = data['seq']\n",
    "        lens = data['len']\n",
    "        if samples > 0:\n",
    "            self.seqs = self.seqs[lens<samples]\n",
    "        self.L = L\n",
    "        self.alph = 4\n",
    "        self.stride = stride\n",
    "        self.sid, self.pos = [], []\n",
    "        for si,s in enumerate(self.seqs):\n",
    "            for i in range(L,len(s),stride):\n",
    "                self.pos.append(i-L)\n",
    "                self.sid.append(si)\n",
    "                \n",
    "    def get_seq(self, i):\n",
    "        si, idx = self.sid[i], self.pos[i]\n",
    "        return self.seqs[si][idx:idx+self.L]\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sid)\n",
    "    \n",
    "    def __getitem__(self, i): \n",
    "        s = self.get_seq(i)\n",
    "        X = torch.from_numpy(s).type(torch.int64)\n",
    "        X = F.one_hot(X, num_classes=self.alph)\n",
    "        X.transpose_(0,1)\n",
    "        X = X.float()\n",
    "        return X, (self.sid[i], self.pos[i])\n",
    "\n",
    "    \n",
    "def embed_seqs(net, dataset, L, stride):\n",
    "    loader = DataLoader(dataset=dataset, batch_size=256, shuffle=False)\n",
    "    net = net.to(device)\n",
    "\n",
    "    embeddings = []\n",
    "    sids = []\n",
    "    pos = []\n",
    "    for data, (si,idx) in tqdm(loader,total=len(loader)):\n",
    "        data = data.to(device)\n",
    "        embed = net(data)\n",
    "        embeddings.append(embed.cpu().data.numpy())\n",
    "        sids.append(si)\n",
    "        pos.append(idx)\n",
    "\n",
    "    embeddings = np.concatenate(embeddings)\n",
    "    embeddings = embeddings.squeeze()\n",
    "    sids = np.concatenate(sids)\n",
    "    pos = np.concatenate(pos)\n",
    "    return embeddings, sids, pos   \n",
    "\n",
    "\n",
    "def nearest_neighbors(embeddings, ensembles=3, leaf=10, dim_expand=2):\n",
    "    N, din = embeddings.shape\n",
    "    dout = int(np.log2(N)*dim_expand)\n",
    "\n",
    "    # project by Gaussian matrix & take the sign bit\n",
    "    P = np.random.randn(din,dout)\n",
    "    embed2 = np.matmul(embeddings, P)\n",
    "    embed2 = (embed2>0).astype(np.int32)\n",
    "    embed2 = embed2.transpose()\n",
    "\n",
    "    # lexical sort after random column permutation\n",
    "    indices = np.zeros((N,ensembles),dtype=np.int32)\n",
    "    for j in range(ensembles):\n",
    "        embed2 = embed2[np.random.permutation(dout),:]\n",
    "        indices[:,j] = np.lexsort(embed2)\n",
    "    indices = indices.transpose()\n",
    "\n",
    "    neighbors = np.zeros((N,leaf * ensembles), np.int64)\n",
    "    for e in range(ensembles):\n",
    "        print(f\"ensemble {e}\")\n",
    "        for i in tqdm(range(N),total=N):\n",
    "            for j in range(leaf):\n",
    "                u, v = indices[e,i], indices[e,(i+j)%N]\n",
    "                idx = j + e*leaf\n",
    "                neighbors[u, idx] = v\n",
    "                neighbors[v, idx] = u\n",
    "                \n",
    "    return neighbors, indices \n",
    "\n",
    "\n",
    "# new projection for every ensemble \n",
    "def nearest_neighbors2(embeddings, ensembles=3, leaf=10, dim_expand=1):\n",
    "    N, din = embeddings.shape\n",
    "    dout = int(np.log2(N)*dim_expand)\n",
    "\n",
    "    # lexical sort after random column permutation\n",
    "    indices = np.zeros((N,ensembles),dtype=np.int32)\n",
    "    print('projection ')\n",
    "    for j in tqdm(range(ensembles),total=ensembles):\n",
    "        P = np.random.randn(din,dout)\n",
    "        embed2 = np.matmul(embeddings, P)\n",
    "        embed2 = (embed2>0)\n",
    "        embed2 = embed2.transpose()\n",
    "        indices[:,j] = np.lexsort(embed2)\n",
    "    indices = indices.transpose()\n",
    "\n",
    "    neighbors = np.zeros((N,leaf * ensembles), np.int64)\n",
    "    for e in range(ensembles):\n",
    "        print(f\"ensemble {e}\")\n",
    "        for i in tqdm(range(N),total=N):\n",
    "            for j in range(leaf):\n",
    "                u, v = indices[e,i], indices[e,(i+j)%N]\n",
    "                idx = j + e*leaf\n",
    "                neighbors[u, idx] = v\n",
    "                neighbors[v, idx] = u\n",
    "                \n",
    "    return neighbors, indices \n",
    "\n",
    "\n",
    "# new projection for every ensemble \n",
    "def nearest_neighbors3(embeddings, ensembles=3, leaf=10, dim_expand=1):\n",
    "    N, din = embeddings.shape\n",
    "    dout = int(np.log2(N)*dim_expand)\n",
    "\n",
    "    # lexical sort after random column permutation\n",
    "    indices = np.zeros((N,ensembles),dtype=np.int64)\n",
    "    print('projection ')\n",
    "    for j in tqdm(range(ensembles),total=ensembles):\n",
    "        P = np.random.randn(din,dout)\n",
    "        embed2 = np.matmul(embeddings, P)\n",
    "        embed2 = (embed2>0)\n",
    "        embed2 = embed2.transpose()\n",
    "        indices[:,j] = np.lexsort(embed2)\n",
    "    indices = indices.transpose()\n",
    "                \n",
    "    return indices \n",
    "\n",
    "\n",
    "def nearest_neighbors4(embeddings, ensembles=3, leaf=10, dim_expand=2):\n",
    "    N, din = embeddings.shape\n",
    "    dout = int(np.log2(N)*dim_expand)\n",
    "\n",
    "    # project by Gaussian matrix & take the sign bit\n",
    "    P = np.random.randn(din,dout)\n",
    "    embed2 = np.matmul(embeddings, P)\n",
    "    embed2 = (embed2>0).astype(np.int32)\n",
    "    embed2 = embed2.transpose()\n",
    "\n",
    "    # lexical sort after random column permutation\n",
    "    indices = np.zeros((N,ensembles),dtype=np.int32)\n",
    "    for j in range(ensembles):\n",
    "        embed2 = embed2[np.random.permutation(dout),:]\n",
    "        indices[:,j] = np.lexsort(embed2)\n",
    "    indices = indices.transpose()\n",
    "    return indices, embed2.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c196812",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pairs(indices, leaf):\n",
    "    X = [np.stack((ind,np.roll(ind,j)),axis=1) for j in range(1,leaf+1) for ind in indices]\n",
    "    X = np.concatenate(X)\n",
    "    return X\n",
    "\n",
    "@njit\n",
    "def get_rank(array):\n",
    "    temp = array.argsort()\n",
    "    ranks = np.empty_like(temp)\n",
    "    ranks[temp] = np.arange(len(array))\n",
    "    return ranks\n",
    "\n",
    "@njit \n",
    "def get_ranks(matrix):\n",
    "    ranks = np.empty_like(matrix)\n",
    "    for j in range(ensembles):\n",
    "        ranks[j] = get_rank(matrix[j])\n",
    "\n",
    "            \n",
    "@njit\n",
    "def pbar(i, total, l=100):\n",
    "    if i % (int(total/l))==0:\n",
    "        print(int(100*i/total))\n",
    "\n",
    "\n",
    "@njit\n",
    "def get_dist_approx(X, emb):\n",
    "    N, D = X.shape[0], emb.shape[1]\n",
    "    d = np.zeros(N)\n",
    "    for r,(i,j) in enumerate(X):\n",
    "        pbar(r,N)\n",
    "        d[r] = 1-np.sum(emb[i,:]*emb[j,:])/D\n",
    "    return d  \n",
    "\n",
    "\n",
    "@njit \n",
    "def cosine_dist(a, b):\n",
    "    a = a / np.linalg.norm(a)\n",
    "    b = b / np.linalg.norm(b)\n",
    "    return 1-np.sum(a*b)\n",
    "\n",
    "\n",
    "@njit\n",
    "def get_dist_exact(X, emb, l=100):\n",
    "    N, D = X.shape[0], emb.shape[1]\n",
    "    d = np.zeros(N,dtype=np.float64)\n",
    "    for r,(i,j) in enumerate(X):\n",
    "        pbar(r,N, l)\n",
    "        d[r] = 1-cosine_dist(emb[i],emb[j])\n",
    "    return d  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d1bf14",
   "metadata": {},
   "source": [
    "# Embed sequences using pre-trained model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c009171f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "num_layers = 8\n",
    "kernel=3\n",
    "groups=4\n",
    "stride_ratio = 1./4\n",
    "device = 'cuda'\n",
    "\n",
    "L = 2**num_layers\n",
    "stride = int(L*stride_ratio)\n",
    "dataset = ViralDataset(samples=2000, L=L, stride=stride)\n",
    "net = load_pretrained_net(groups=groups, kernel=kernel, num_layers=num_layers,)\n",
    "embeddings, sids, pos = embed_seqs(net, dataset, L, stride)\n",
    "np.savez('embed',embeddings=embeddings, sids=sids, pos=pos)\n",
    "embeddings.shape, sids.shape, pos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b98e968",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('embed.npz')\n",
    "embeddings, sids, pos = data['embeddings'], data['sids'], data['pos']\n",
    "indices = np.load('indices.npz',allow_pickle=True)['indices']\n",
    "\n",
    "embeddings.shape, sids.shape, pos.shape, indices.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1673da",
   "metadata": {},
   "source": [
    "# Nearest neighbors in embedding space "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8f8746",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "            \n",
    "ensembles = 10\n",
    "leaf = 100\n",
    "dim_expand = 5\n",
    "\n",
    "indices = nearest_neighbors3(embeddings, ensembles=ensembles, leaf=leaf, dim_expand=dim_expand)\n",
    "np.savez('indices',indices=indices)\n",
    "\n",
    "indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8732ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "X = get_pairs(indices=indices, leaf=leaf)\n",
    "\n",
    "ED = get_dist_exact(X, embeddings, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ae1730",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_idx = np.argsort(ED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544351dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "v2s = lambda x: \"\".join([chr(a+ord('a')) for a in x])\n",
    "num_samples = 1000\n",
    "x=np.empty(num_samples)\n",
    "y = np.empty(num_samples)\n",
    "meta = [None]*num_samples\n",
    "for ri in range(num_samples):\n",
    "    r = np.random.randint(num_samples)\n",
    "    si = sorted_idx[r]\n",
    "    i, j = X[si,:]\n",
    "    s1, s2 = dataset.get_seq(i), dataset.get_seq(j)\n",
    "    d = editdistance.eval(s1, s2)/L\n",
    "    s1, s2 = v2s(s1), v2s(s2)\n",
    "    meta[ri] = f\"{s1[:10]},\\n {s2[:10]}\"\n",
    "    x[ri], y[ri] = ED[si], d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f385cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'embed dist': x, 'edit dist': y, 'meta': meta})\n",
    "ex.scatter(df, x='edit dist', y='embed dist', hover_name='meta' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9dfb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex.line(ED[sorted_idx[::1000]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5935db3",
   "metadata": {},
   "source": [
    "## TSNE plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c6339c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "embed_low = TSNE(n_components=3).fit_transform(embeddings)\n",
    "embed_low.shape \n",
    "\n",
    "labels = [ids[sid].split(' ')[0] for sid in sids]\n",
    "ex.scatter_3d(embed_low, x=0, y=1, z=2, color=labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
